# Project_Wrangle_And_Analyze_Data

The aim of this project was to perform key data analysis skills, such as data gathering, assessing data quality and tidiness, and cleaning and visualizing the data and providing insights into final data.
The project focused on data captured from a twitter page called WeRateDogs, where people post information about their dogs where they can be rated. The data used originated from different sources, with tweet data for 5000+ tweets, with information on a dog's rating, dog name, and dog "stage outlined as follows:
</br>
 <li> archived data taken from twitter_archive-enhanced.csv file </li>
 <li> retweet count and favorite count on the dogs, taken from the twitter page using a twitter API (tweepy) </li>
 <li> image prediction data from a file image_predictions.tsv - this file contains data predicting the probability of the type of dog in the image </li>
</br>
The utilities used to complete the project included Jupyter notebook, Python, Pandas and Numpy. 
</br> 
The work done for the project was broken down as follows:
<ul>1. Data gathering - extracting the data from the sources listed above </ul>
<ul>2. Asessing the Data visually and programmatically for quality and tidiness </ul>
<ul>3. Cleaning the data </ul> 
<ul>4. Merging the cleaned data and storing in new file twitter_archive_master.csv </ul>
<ul>5. Analyzing and visualizing the data to provide insights into the data. Areas looked at were: </ul>
      <li>Dog breeds with the most favorites</li>
      <li>Top popular dog names</li>
      <li>Sources used to send tweets</li>
      <li>Dogs with the most retweets</li>
      <li>Dogs with the highest ratings</li>
      <li>Retweets vs favorites</li>
      <li>Accuracy of image prediction</li>
